{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataset and popularity threshold P\n",
    "dataset_name=\"movielens20m\" # movielens100k, movielens20m, amazon\n",
    "popularity_threshold=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytrec_eval\n",
    "\n",
    "from decimal import Decimal\n",
    "import scipy.stats as st\n",
    "from itertools import combinations\n",
    "from spotlight.datasets import movielens, amazon, goodbooks\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.evaluation import mrr_score, precision_recall_score\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "from popularity import PopularityModel\n",
    "from randomm import RandomModel\n",
    "\n",
    "\n",
    "# evaluation function based on pytrec_eval\n",
    "def evaluate(interactions, model, topk):\n",
    "\n",
    "    # create qrel\n",
    "    qrel = {}\n",
    "    for (u, i) in zip(interactions.user_ids,\n",
    "                      interactions.item_ids):\n",
    "        u = str(u)\n",
    "        i = str(i)\n",
    "        if u not in qrel:\n",
    "            qrel[u] = {}\n",
    "        qrel[u][i] = 1\n",
    "\n",
    "    # relevance evaluator\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "        qrel, pytrec_eval.supported_measures)\n",
    "\n",
    "    # create run\n",
    "    run = {}\n",
    "    for uid in np.unique(interactions.user_ids):\n",
    "        predictions = -model.predict(user_ids=uid)\n",
    "        predictions_argsort = predictions.argsort()[:topk]\n",
    "        if str(uid) not in run:\n",
    "            run[str(uid)] = {}\n",
    "        for iid in predictions_argsort:\n",
    "            run[str(uid)][str(iid)] = float(-predictions[iid])\n",
    "\n",
    "    return evaluator.evaluate(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build popular and unpopular sample sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples contains 20,000,263 interactions with average popularity 1.35E+04\n",
      "\n",
      "\n",
      "Total population (popularity < 30000): 17,417,627\n",
      "\n",
      "\n",
      "Popular samples contains 16,000,211 interactions with average popularity 1.46E+04\n",
      "\n",
      "\n",
      "Unpopular samples contains 4,000,052 interactions with average popularity 9.08E+03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if dataset_name == \"movielens100k\":\n",
    "    ds = movielens.get_movielens_dataset(variant='100K')\n",
    "elif dataset_name == \"movielens20m\":\n",
    "    ds = movielens.get_movielens_dataset(variant='20M')\n",
    "elif dataset_name == \"amazon\":\n",
    "    ds = amazon.get_amazon_dataset()\n",
    "elif dataset_name == \"goodbook\":\n",
    "    ds = goodbooks.get_goodbooks_dataset()\n",
    "    ds.ratings = ds.ratings.astype(np.float32)\n",
    "else:\n",
    "    print(\"unknown dataset\")\n",
    "\n",
    "# find the rating frequency of each item\n",
    "item_freq = dict()\n",
    "for uid, iid in zip(ds.user_ids, ds.item_ids):\n",
    "    f = item_freq.setdefault(iid, 0)\n",
    "    f += 1\n",
    "    item_freq[iid] = f\n",
    "\n",
    "# get the corresponding array for popularity\n",
    "pops = []\n",
    "for iid in ds.item_ids:\n",
    "    pops.append(item_freq[iid])\n",
    "\n",
    "ds.weights = np.array(pops, dtype=np.float64)\n",
    "# ds.weights /= sum(ds.weights)\n",
    "\n",
    "print(\"\"\"\n",
    "Total samples contains %s interactions with average popularity %.2E\n",
    "\"\"\" % (format(len(ds.user_ids), ','), Decimal(np.mean(ds.weights))))\n",
    "\n",
    "sample_size = int(0.2 * len(ds.user_ids))\n",
    "indices = np.array([x for x in range(len(ds.user_ids))], np.int32)\n",
    "\n",
    "print(\"\"\"\n",
    "Total population (popularity < %d): %s\n",
    "\"\"\" % (popularity_threshold, format(sum(ds.weights < popularity_threshold), ',')))\n",
    "\n",
    "unpopular_indices = np.random.choice(a=indices[ds.weights < popularity_threshold],\n",
    "                                     size=sample_size,\n",
    "                                     replace=False)\n",
    "\n",
    "popular_indices = np.ones(len(ds.user_ids), dtype=bool)\n",
    "\n",
    "popular_indices[unpopular_indices] = False\n",
    "\n",
    "# build a popular dataset\n",
    "ds_popular = Interactions(user_ids=ds.user_ids[popular_indices],\n",
    "                          item_ids=ds.item_ids[popular_indices],\n",
    "                          ratings=ds.ratings[popular_indices],\n",
    "                          timestamps=ds.timestamps[popular_indices],\n",
    "                          weights=ds.weights[popular_indices],\n",
    "                          num_users=ds.num_users,\n",
    "                          num_items=ds.num_items)\n",
    "\n",
    "print(\"\"\"\n",
    "Popular samples contains %s interactions with average popularity %.2E\n",
    "\"\"\" % (format(len(ds_popular.user_ids), ','), Decimal(np.mean(ds_popular.weights))))\n",
    "\n",
    "ds_unpopular = Interactions(user_ids=ds.user_ids[unpopular_indices],\n",
    "                            item_ids=ds.item_ids[unpopular_indices],\n",
    "                            ratings=ds.ratings[unpopular_indices],\n",
    "                            timestamps=ds.timestamps[unpopular_indices],\n",
    "                            weights=ds.weights[unpopular_indices],\n",
    "                            num_users=ds.num_users,\n",
    "                            num_items=ds.num_items)\n",
    "\n",
    "print(\"\"\"\n",
    "Unpopular samples contains %s interactions with average popularity %.2E\n",
    "\"\"\" % (format(len(ds_unpopular.user_ids), ','), Decimal(np.mean(ds_unpopular.weights))))\n",
    "\n",
    "# split the popular interactions\n",
    "test_ratio = float(sample_size / len(ds_popular.user_ids))\n",
    "\n",
    "ds_popular_train, ds_popular_test = random_train_test_split(\n",
    "    ds_popular, test_percentage=test_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- random -----\n",
      "\tMRR@20  (Biased): 0.003912\n",
      "\tNDCG@20 (Biased): 0.000752\n",
      "\tMRR@20  (UnBiased): 0.003965\n",
      "\tNDCG@20 (UnBiased): 0.000718\n",
      "\n",
      "----- popularity -----\n",
      "\tMRR@20  (Biased): 0.256568\n",
      "\tNDCG@20 (Biased): 0.098099\n",
      "\tMRR@20  (UnBiased): 0.000000\n",
      "\tNDCG@20 (UnBiased): 0.000000\n",
      "\n",
      "----- explicit -----\n",
      "\tMRR@20  (Biased): 0.179767\n",
      "\tNDCG@20 (Biased): 0.071821\n",
      "\tMRR@20  (UnBiased): 0.022733\n",
      "\tNDCG@20 (UnBiased): 0.008036\n",
      "\n",
      "----- bpr -----\n",
      "\tMRR@20  (Biased): 0.255316\n",
      "\tNDCG@20 (Biased): 0.099809\n",
      "\tMRR@20  (UnBiased): 0.000088\n",
      "\tNDCG@20 (UnBiased): 0.000006\n",
      "\n",
      "----- warp -----\n",
      "\tMRR@20  (Biased): 0.262649\n",
      "\tNDCG@20 (Biased): 0.106603\n",
      "\tMRR@20  (UnBiased): 0.030897\n",
      "\tNDCG@20 (UnBiased): 0.005154\n"
     ]
    }
   ],
   "source": [
    "# fix model's parameters\n",
    "LATENT_DIM = 32\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 256\n",
    "L2 = 1e-6\n",
    "LEARNING_RATE = 1e-3\n",
    "topk = 20\n",
    "\n",
    "mrr_biased = []\n",
    "ndcg_biased = []\n",
    "mrr_unbiased = []\n",
    "ndcg_unbiased = []\n",
    "\n",
    "model_names = [\"random\", \"popularity\", \"explicit\", \"bpr\", \"warp\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    # fit the model\n",
    "    if model_name == \"random\":\n",
    "        model = RandomModel()\n",
    "\n",
    "    elif model_name == \"popularity\":\n",
    "        model = PopularityModel(k=topk)\n",
    "\n",
    "    elif model_name == \"explicit\":\n",
    "        model = ExplicitFactorizationModel(loss='regression',\n",
    "                                           embedding_dim=LATENT_DIM,\n",
    "                                           n_iter=NUM_EPOCHS,\n",
    "                                           learning_rate=LEARNING_RATE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           l2=L2)\n",
    "\n",
    "    elif model_name == \"bpr\":\n",
    "        model = ImplicitFactorizationModel(loss='bpr',\n",
    "                                           embedding_dim=LATENT_DIM,\n",
    "                                           n_iter=NUM_EPOCHS,\n",
    "                                           learning_rate=LEARNING_RATE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           l2=L2)\n",
    "\n",
    "    elif model_name == \"warp\":\n",
    "        model = ImplicitFactorizationModel(loss='adaptive_hinge',\n",
    "                                           embedding_dim=LATENT_DIM,\n",
    "                                           n_iter=NUM_EPOCHS,\n",
    "                                           learning_rate=LEARNING_RATE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           l2=L2)\n",
    "\n",
    "    else:\n",
    "        print('Unknown model name')\n",
    "\n",
    "    # fit the model to training set\n",
    "    model.fit(ds_popular_train)\n",
    "\n",
    "    # evaluate on the biased test set\n",
    "    results = evaluate(ds_popular_test, model, topk)\n",
    "\n",
    "    mrr_biased.append([query_measures['recip_rank']\n",
    "                       for uid, query_measures in sorted(results.items())])\n",
    "    ndcg_biased.append([query_measures['ndcg']\n",
    "                        for uid, query_measures in sorted(results.items())])\n",
    "\n",
    "    # evaluate the model on the biased dataset\n",
    "    print()\n",
    "    print('-'*5, model_name, '-'*5)\n",
    "    print('\\tMRR@%d  (Biased): %f' %\n",
    "          (topk, pytrec_eval.compute_aggregated_measure(measure='recip_rank', values=mrr_biased[-1])))\n",
    "    print('\\tNDCG@%d (Biased): %f' %\n",
    "          (topk, pytrec_eval.compute_aggregated_measure(measure='ndcg', values=ndcg_biased[-1])))\n",
    "\n",
    "    # evaluate on the unbiased test set\n",
    "    results = evaluate(ds_unpopular, model, topk)\n",
    "\n",
    "    mrr_unbiased.append([query_measures['recip_rank']\n",
    "                         for uid, query_measures in sorted(results.items())])\n",
    "    ndcg_unbiased.append([query_measures['ndcg']\n",
    "                          for uid, query_measures in sorted(results.items())])\n",
    "\n",
    "    # evaluate the model on the biased dataset\n",
    "    print('\\tMRR@%d  (UnBiased): %f' %\n",
    "          (topk, pytrec_eval.compute_aggregated_measure(measure='recip_rank', values=mrr_unbiased[-1])))\n",
    "    print('\\tNDCG@%d (UnBiased): %f' %\n",
    "          (topk, pytrec_eval.compute_aggregated_measure(measure='ndcg', values=ndcg_unbiased[-1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
